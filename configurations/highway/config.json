{
  "ML": {
      "Agent": {
        "actor_fc_layer_params": [256, 256, 128],
        "critic_joint_fc_layer_params": [256, 256, 128],
        "actor_learning_rate": 3e-4,
        "critic_learning_rate": 3e-4,
        "alpha_learning_rate": 3e-4,
        "target_update_tau": 0.05,
        "target_update_period": 1,
        "gamma": 0.995,
        "reward_scale_factor": 1.0,
        "gradient_clipping": 10.0, 
        "agent_name": "sac_agent",
        "debug_summaries": "True",
        "replay_buffer_capacity": 100000,
        "max_ckpts_to_keep": 3,
        "parallel_buffer_calls": 3,
        "batch_size": 256,
        "num_parallel_environments": 30,
        "buffer_num_steps": 2,
        "buffer_prefetch": 3,
        "checkpoint_path": "configurations/highway/checkpoints/"
      },
      "Evaluator": {
        "max_steps": 60,
        "collision_penalty": -10.0,
        "goal_reward": 10.0
      },
      "Observer": {
        "velocity_range": [0, 30],
        "theta_range": [-3.14, 3.14],
        "normalization_enabled": true,
        "max_num_agents": 2,
        "n_nearest_agents": 5,
        "max_vel": 30.0,
        "max_lon": 500.0
      },
      "Runner": {
        "number_of_collections": 5000000,
        "initial_collection_steps": 100,
        "collection_episodes_per_cycle": 1,
        "evaluate_every_n_steps": 2500,
        "evaluation_steps": 25,
        "summary_path": "configurations/highway/summaries/"
      },
      "DynamicModel": {
        "action_dimension": 2,
        "action_num": 1,
        "actions_lower_bound": [-1.0, -0.15],
        "actions_upper_bound": [1.0, 0.15]
      }
  },
  "World": {
    "remove_agents_out_of_map" : true
  }
}
