{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adverserial Imitation Learning\n",
    "\n",
    "Generative Adversarial Imitation Learning (GAIL) was first proposed in the paper [Generative Adversarial Imitation Learning](https://arxiv.org/abs/1606.03476) by Jonathan Ho and Stefano Ermon. \n",
    "The project task is to implement the Generative Adverserial Imitation Learning model for driving scenarios using the bark-simulator.\n",
    "\n",
    "GAIL is based in the setting of reinforcement learning.\n",
    "Reinforcment learning is an area of machine learning concerned with how agents take actions in an environment in order to maximize the sum of rewards.\n",
    "So what a GAIL agent does is take actions in the bark environment and measure the resulting state of the agent and the world.\n",
    "\n",
    "As the name says we are more specifically located in the setting of Imitation Learning. \n",
    "Our agent will try to learn a policy that mimics demonstrations.\n",
    "We extract these demonstrations as Expert Trajectories from the interaction dataset by replaying the dataset in the bark simulator.\n",
    "This gives us the expert rollouts which are a set of state action pairs representing the expert knowledge. \n",
    "In a RL setting, we need some sort of reward to update the agents network parameters.\n",
    "\n",
    "In the GAIL approach we get the reward from an adversarial game:\n",
    "Another discriminator network gets fed the agent rollouts and the experts rollouts and wants to classify between them accurately.\n",
    "The agent network wants to fool the discriminator by minimizing the probability to get classified as fake.\n",
    "The classification as fake or not that is output by the discriminator is the reward we feed into our agent network.\n",
    "To minimize the classification as fake the agent network needs to mimic the experts demonstration and by doing so learn the experts policy.\n",
    "\n",
    "\n",
    "<img width=70% src=\"files/data/gail_overview.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project task\n",
    "\n",
    "The project task is to implement the Generative Adverserial Imitation Learning model for driving scenarios using the bark-simulator.\n",
    "\n",
    "### Port GAIL driver to bark\n",
    "Do not reimplement gail, but use an existing implementation and bring it to bark.\n",
    "We chose [TF2RL](https://github.com/keiohta/tf2rl).\n",
    "\n",
    "### Train the GAIL agent on the Interaction Dataset\n",
    "As a data source, we will use the interaction dataset: https://arxiv.org/abs/1910.03088 . Here,\n",
    "w e are interested in the merging scenes: deu_merging_mt and chn_merging_zs\n",
    "Have a look how the Interaction Dataset is integrated in bark: https://github.com/bark-\n",
    "simulator/bark/blob/setup_tutorials/docs/tutorials/04_interaction_dataset.ipynb (NOte that\n",
    "the dataset itsself is NOT enclosed with bark due to license limitations).\n",
    "Train + validate agents individually for each scenes: In the first step, replace one agent and use\n",
    "all other agents from the dataset: The gail agent navigates safely. Afterwards, replace more\n",
    "\n",
    "### Evaluate the agent\n",
    "Exchange the trained models on the German and the Chinese map: how well is the\n",
    "generalization?\n",
    "ONLY place gail agents on the map: Can we generate scenes that \"look alike\" the real scenarios?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expert Trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Expert Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import bark\n",
    "from pprint import pprint\n",
    "from bark_ml.library_wrappers.lib_tf2rl.generate_expert_trajectories import *\n",
    "\n",
    "tracks_folder = os.path.join(os.getcwd(), 'data')\n",
    "map_file = os.path.join(os.getcwd(), 'data/DR_DEU_Merging_MT_v01_shifted.xodr')\n",
    "known_key = ('DR_DEU_Merging_MT_v01_shifted', 'vehicle_tracks_013')\n",
    "ego_agent = 66\n",
    "\n",
    "param_server = create_parameter_servers_for_scenarios(map_file, tracks_folder)[known_key]\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"TrackIds\"] = [\n",
    "    63, 64, 65, 66, 67, 68]\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"StartTs\"] = 232000\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"EndTs\"] = 259000\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"EgoTrackId\"] = ego_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "expert_trajectories = generate_expert_trajectories_for_scenario(param_server, sim_time_step=200, renderer=\"matplotlib_jupyter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The simulation gives us a number of observations and actions for the experts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations for the agent 66\n",
      "\n",
      "[array([0.54990917, 0.55034685, 0.49115214, 0.02195392, 0.54979807,\n",
      "       0.55021369, 0.48701411, 0.01664484, 0.55023372, 0.55031705,\n",
      "       0.48717329, 0.01795783, 0.55020285, 0.55017918, 0.48908314,\n",
      "       0.01927594]),\n",
      " array([0.5498873 , 0.5503481 , 0.49115214, 0.02188459, 0.54978162,\n",
      "       0.55021507, 0.48701411, 0.0162844 , 0.5502159 , 0.55031848,\n",
      "       0.48733243, 0.01776604, 0.55018389, 0.55018038, 0.48940146,\n",
      "       0.0182608 ]),\n",
      " array([0.54986548, 0.55034935, 0.49099299, 0.02179474, 0.54976547,\n",
      "       0.55021638, 0.48685497, 0.01594391, 0.55019826, 0.55031985,\n",
      "       0.48733243, 0.01757585, 0.55016589, 0.55018145, 0.4895606 ,\n",
      "       0.0172271 ]),\n",
      " array([0.54984373, 0.55035061, 0.49099299, 0.02165496, 0.54974967,\n",
      "       0.55021775, 0.48685497, 0.01561338, 0.55018073, 0.55032122,\n",
      "       0.48733243, 0.01744546, 0.55014902, 0.55018252, 0.48971975,\n",
      "       0.01617412]),\n",
      " array([0.54982221, 0.55035186, 0.49083385, 0.02145529, 0.54973418,\n",
      "       0.550219  , 0.48685497, 0.0153219 , 0.55016333, 0.55032271,\n",
      "       0.48733243, 0.01744546, 0.55013311, 0.55018365, 0.4895606 ,\n",
      "       0.01517233])]\n"
     ]
    }
   ],
   "source": [
    "# Small number of observations for our agent\n",
    "print(f'Observations for the agent {ego_agent}\\n')\n",
    "pprint(expert_trajectories[ego_agent]['obs'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions of the agent 66\n",
      "\n",
      "[[0.0, -0.0003466568835577833],\n",
      " [-0.004201827340902073, -0.00030657489373432596],\n",
      " [0.002051691485158719, -0.00035168134700955115],\n",
      " [-0.004200119214675828, -0.0005815505374677107],\n",
      " [0.002049979741333098, -0.0009188447324507322]]\n"
     ]
    }
   ],
   "source": [
    "# Small number of actions for our agent\n",
    "print(f'Actions of the agent {ego_agent}\\n')\n",
    "pprint(expert_trajectories[ego_agent]['act'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAIL implementation\n",
    "\n",
    "### TF2RL implementation\n",
    "We have chosen an off the shelf implementation, thelibrary [TF2RL](https://github.com/keiohta/tf2rl). It implements several reinforcement algorithms and training methods in [tensorflow 2](https://www.tensorflow.org/guide/effective_tf2). \n",
    "\n",
    "The GAIL agent is built up as follows:\n",
    "* __Generator:__ A complete DDPG agent with the actor and critic networks. Both of them has 2-2 hidden layers.\n",
    "* __Discriminator:__ A normal discriminator network with 2 hidden layers.\n",
    "\n",
    "In this respect the agent is not in the traditional GAIL setup with 2 neural networks, but instead it actually has 5 networks, since the DDPG agent it self has got 4 of them for greater stability during training. The DDPG agent's critic network basically receives the judgement of the Discriminator network as the reward from the environment and its training aims to maximize this reward.\n",
    "\n",
    "### Integration into BARK\n",
    "The integration of the TF2RL based GAIL agent is done along existing BARK concepts and has been done in the following most important classes:\n",
    "* __TF2RLWrapper:__ Wraps the BARK runtime to match the expectations of tf2rl about the environment. The observation and action normalization also takes place here.\n",
    "    * file: `bark_ml/library_wrappers/lib_tf2rl/tf2rl_wrapper.py`\n",
    "* __BehaviorTF2RLAgent:__ Base class for TF2RL based agents.\n",
    "    * file: `bark_ml/library_wrappers/lib_tf2rl/agents/tf2rl_agent.py`\n",
    "* __BehaviorGAILAgent:__ The TF2RL based GAIL agent.\n",
    "    * file: `bark_ml/library_wrappers/lib_tf2rl/agents/gail_agent.py`\n",
    "* __TF2RLRunner:__ Base class for TF2RL based runners.\n",
    "    * file: `bark_ml/library_wrappers/lib_tf2rl/runners/tf2rl_runner.py`\n",
    "* __GAILRunner:__ The TF2RL based GAIL runner.\n",
    "    * file: `bark_ml/library_wrappers/lib_tf2rl/runners/gail_runner.py`\n",
    "    \n",
    "In the followings the training process is shown. Later the performance of a pre-trained agent can be visualized.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "The parameters which can be set on demand:\n",
    "* The number of steps to train for.\n",
    "* The frequency of testing during training\n",
    "* The number of episodes in each testing round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Costumise some parameters here!!! #\n",
    "\n",
    "max_steps = 100000          # Number of steps to train for.\n",
    "test_interval = 1000       # test in every ... steps.\n",
    "test_episodes = 5          # number of test episodes.\n",
    "gpu = 0                    # use -1 for cpu only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# BARK imports\n",
    "from bark_project.bark.runtime.commons.parameters import ParameterServer\n",
    "from bark.runtime.viewer.matplotlib_viewer import MPViewer\n",
    "from bark.runtime.viewer.video_renderer import VideoRenderer\n",
    "\n",
    "# BARK-ML imports\n",
    "from bark_ml.environments.blueprints import ContinuousHighwayBlueprint, \\\n",
    "  ContinuousMergingBlueprint, ContinuousIntersectionBlueprint, GailMergingBlueprint\n",
    "from bark_ml.environments.single_agent_runtime import SingleAgentRuntime\n",
    "from bark_ml.library_wrappers.lib_tf2rl.tf2rl_wrapper import TF2RLWrapper\n",
    "from bark_ml.library_wrappers.lib_tf2rl.agents.gail_agent import BehaviorGAILAgent\n",
    "from bark_ml.library_wrappers.lib_tf2rl.runners.gail_runner import GAILRunner\n",
    "from bark_ml.library_wrappers.lib_tf2rl.load_expert_trajectories import load_expert_trajectories\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell deletes the previous logs and launches tensorboard. After tensorboard has launced, please go on to the next cell and start the training. The tensorboard window refreshes it self in every 30 secs, but you can also refresh it by hand in the top right corner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-df3834f07f611e39\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-df3834f07f611e39\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# launching tensorboard and deleting the previous runs logdirs:\n",
    "%rm -r \"data/logs\"\n",
    "%mkdir \"data/logs\"\n",
    "%tensorboard --logdir \"data/logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ferenc/.cache/bazel/_bazel_ferenc/d27c94d45ef586b197c709d8101d6384/execroot/bark_ml/bazel-out/k8-fastbuild/bin/docs/report/run.runfiles/bark_project/bark/runtime/commons/xodr_parser.py:108: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  if lane.find(\"userData\"):\n",
      "15:51:53.674 [INFO] (trainer.py:65) Restored None\n",
      "15:51:53.752 [INFO] (irl_trainer.py:74) Total Epi:     1 Steps:       6 Episode Steps:     6 Return: -1.0000 FPS: 83.13\n",
      "15:53:05.931 [INFO] (irl_trainer.py:74) Total Epi:     2 Steps:       9 Episode Steps:     3 Return: -1.0000 FPS: 413.04\n",
      "15:53:05.940 [INFO] (irl_trainer.py:74) Total Epi:     3 Steps:      13 Episode Steps:     4 Return: -1.0000 FPS: 517.71\n",
      "15:53:05.958 [INFO] (irl_trainer.py:74) Total Epi:     4 Steps:      22 Episode Steps:     9 Return: -1.0000 FPS: 630.98\n",
      "15:53:05.968 [INFO] (irl_trainer.py:74) Total Epi:     5 Steps:      28 Episode Steps:     6 Return: -1.0000 FPS: 631.70\n",
      "15:53:05.977 [INFO] (irl_trainer.py:74) Total Epi:     6 Steps:      32 Episode Steps:     4 Return: -1.0000 FPS: 565.01\n",
      "15:53:06.005 [INFO] (irl_trainer.py:74) Total Epi:     7 Steps:      50 Episode Steps:    18 Return: -1.0000 FPS: 668.23\n",
      "15:53:06.038 [INFO] (irl_trainer.py:74) Total Epi:     8 Steps:      71 Episode Steps:    21 Return: -1.0000 FPS: 671.62\n",
      "15:53:06.045 [INFO] (irl_trainer.py:74) Total Epi:     9 Steps:      73 Episode Steps:     2 Return: -1.0000 FPS: 402.54\n",
      "15:53:06.053 [INFO] (irl_trainer.py:74) Total Epi:    10 Steps:      76 Episode Steps:     3 Return: -1.0000 FPS: 457.38\n",
      "15:53:06.063 [INFO] (irl_trainer.py:74) Total Epi:    11 Steps:      81 Episode Steps:     5 Return: -1.0000 FPS: 590.68\n",
      "15:53:06.110 [INFO] (irl_trainer.py:74) Total Epi:    12 Steps:     111 Episode Steps:    30 Return: -1.0000 FPS: 689.89\n",
      "15:53:06.117 [INFO] (irl_trainer.py:74) Total Epi:    13 Steps:     114 Episode Steps:     3 Return: -1.0000 FPS: 503.31\n",
      "15:53:06.129 [INFO] (irl_trainer.py:74) Total Epi:    14 Steps:     118 Episode Steps:     4 Return: -1.0000 FPS: 396.32\n",
      "15:53:06.141 [INFO] (irl_trainer.py:74) Total Epi:    15 Steps:     123 Episode Steps:     5 Return: -1.0000 FPS: 514.96\n",
      "15:53:06.155 [INFO] (irl_trainer.py:74) Total Epi:    16 Steps:     131 Episode Steps:     8 Return: -1.0000 FPS: 668.12\n",
      "15:53:06.166 [INFO] (irl_trainer.py:74) Total Epi:    17 Steps:     136 Episode Steps:     5 Return: -1.0000 FPS: 591.33\n",
      "15:53:06.181 [INFO] (irl_trainer.py:74) Total Epi:    18 Steps:     144 Episode Steps:     8 Return: -1.0000 FPS: 592.96\n",
      "15:53:06.201 [INFO] (irl_trainer.py:74) Total Epi:    19 Steps:     158 Episode Steps:    14 Return: -1.0000 FPS: 732.06\n",
      "15:53:06.216 [INFO] (irl_trainer.py:74) Total Epi:    20 Steps:     160 Episode Steps:     2 Return: -1.0000 FPS: 158.56\n",
      "15:53:06.237 [INFO] (irl_trainer.py:74) Total Epi:    21 Steps:     172 Episode Steps:    12 Return: -1.0000 FPS: 687.09\n",
      "15:53:06.247 [INFO] (irl_trainer.py:74) Total Epi:    22 Steps:     176 Episode Steps:     4 Return: -1.0000 FPS: 478.55\n",
      "15:53:06.262 [INFO] (irl_trainer.py:74) Total Epi:    23 Steps:     179 Episode Steps:     3 Return: -1.0000 FPS: 281.02\n",
      "15:53:06.270 [INFO] (irl_trainer.py:74) Total Epi:    24 Steps:     181 Episode Steps:     2 Return: -1.0000 FPS: 369.52\n",
      "15:53:06.279 [INFO] (irl_trainer.py:74) Total Epi:    25 Steps:     185 Episode Steps:     4 Return: -1.0000 FPS: 580.14\n",
      "15:53:06.291 [INFO] (irl_trainer.py:74) Total Epi:    26 Steps:     193 Episode Steps:     8 Return: -1.0000 FPS: 702.70\n",
      "15:53:06.327 [INFO] (irl_trainer.py:74) Total Epi:    27 Steps:     214 Episode Steps:    21 Return:  1.0000 FPS: 625.85\n",
      "15:53:06.341 [INFO] (irl_trainer.py:74) Total Epi:    28 Steps:     220 Episode Steps:     6 Return: -1.0000 FPS: 483.04\n",
      "15:53:06.355 [INFO] (irl_trainer.py:74) Total Epi:    29 Steps:     223 Episode Steps:     3 Return: -1.0000 FPS: 282.36\n",
      "15:53:06.368 [INFO] (irl_trainer.py:74) Total Epi:    30 Steps:     228 Episode Steps:     5 Return: -1.0000 FPS: 434.95\n",
      "15:53:06.380 [INFO] (irl_trainer.py:74) Total Epi:    31 Steps:     231 Episode Steps:     3 Return: -1.0000 FPS: 334.71\n",
      "15:53:06.391 [INFO] (irl_trainer.py:74) Total Epi:    32 Steps:     236 Episode Steps:     5 Return: -1.0000 FPS: 615.33\n",
      "15:53:06.403 [INFO] (irl_trainer.py:74) Total Epi:    33 Steps:     243 Episode Steps:     7 Return: -1.0000 FPS: 660.61\n",
      "15:53:06.410 [INFO] (irl_trainer.py:74) Total Epi:    34 Steps:     246 Episode Steps:     3 Return: -1.0000 FPS: 509.21\n",
      "15:53:06.421 [INFO] (irl_trainer.py:74) Total Epi:    35 Steps:     249 Episode Steps:     3 Return: -1.0000 FPS: 336.79\n",
      "15:53:06.436 [INFO] (irl_trainer.py:74) Total Epi:    36 Steps:     259 Episode Steps:    10 Return: -1.0000 FPS: 732.81\n",
      "15:53:06.446 [INFO] (irl_trainer.py:74) Total Epi:    37 Steps:     264 Episode Steps:     5 Return: -1.0000 FPS: 606.55\n",
      "15:53:06.457 [INFO] (irl_trainer.py:74) Total Epi:    38 Steps:     270 Episode Steps:     6 Return: -1.0000 FPS: 647.02\n",
      "15:53:06.470 [INFO] (irl_trainer.py:74) Total Epi:    39 Steps:     275 Episode Steps:     5 Return: -1.0000 FPS: 440.98\n",
      "15:53:06.478 [INFO] (irl_trainer.py:74) Total Epi:    40 Steps:     279 Episode Steps:     4 Return: -1.0000 FPS: 586.73\n",
      "15:53:06.489 [INFO] (irl_trainer.py:74) Total Epi:    41 Steps:     285 Episode Steps:     6 Return: -1.0000 FPS: 632.63\n",
      "15:53:06.500 [INFO] (irl_trainer.py:74) Total Epi:    42 Steps:     291 Episode Steps:     6 Return: -1.0000 FPS: 631.27\n",
      "15:53:06.532 [INFO] (irl_trainer.py:74) Total Epi:    43 Steps:     312 Episode Steps:    21 Return: -1.0000 FPS: 693.70\n",
      "15:53:06.550 [INFO] (irl_trainer.py:74) Total Epi:    44 Steps:     320 Episode Steps:     8 Return: -1.0000 FPS: 489.53\n",
      "15:53:06.561 [INFO] (irl_trainer.py:74) Total Epi:    45 Steps:     324 Episode Steps:     4 Return: -1.0000 FPS: 443.65\n",
      "15:53:06.573 [INFO] (irl_trainer.py:74) Total Epi:    46 Steps:     328 Episode Steps:     4 Return: -1.0000 FPS: 386.35\n",
      "15:53:06.584 [INFO] (irl_trainer.py:74) Total Epi:    47 Steps:     332 Episode Steps:     4 Return: -1.0000 FPS: 500.77\n",
      "15:53:06.600 [INFO] (irl_trainer.py:74) Total Epi:    48 Steps:     342 Episode Steps:    10 Return: -1.0000 FPS: 672.43\n",
      "15:53:06.608 [INFO] (irl_trainer.py:74) Total Epi:    49 Steps:     346 Episode Steps:     4 Return: -1.0000 FPS: 572.23\n",
      "15:53:06.617 [INFO] (irl_trainer.py:74) Total Epi:    50 Steps:     348 Episode Steps:     2 Return: -1.0000 FPS: 273.20\n",
      "15:53:06.625 [INFO] (irl_trainer.py:74) Total Epi:    51 Steps:     351 Episode Steps:     3 Return: -1.0000 FPS: 464.05\n",
      "15:53:06.634 [INFO] (irl_trainer.py:74) Total Epi:    52 Steps:     355 Episode Steps:     4 Return: -1.0000 FPS: 559.06\n",
      "15:53:06.645 [INFO] (irl_trainer.py:74) Total Epi:    53 Steps:     361 Episode Steps:     6 Return: -1.0000 FPS: 607.01\n",
      "15:53:06.655 [INFO] (irl_trainer.py:74) Total Epi:    54 Steps:     363 Episode Steps:     2 Return: -1.0000 FPS: 320.76\n",
      "15:53:06.667 [INFO] (irl_trainer.py:74) Total Epi:    55 Steps:     366 Episode Steps:     3 Return: -1.0000 FPS: 353.47\n",
      "15:53:06.677 [INFO] (irl_trainer.py:74) Total Epi:    56 Steps:     371 Episode Steps:     5 Return: -1.0000 FPS: 597.12\n",
      "15:53:06.683 [INFO] (irl_trainer.py:74) Total Epi:    57 Steps:     373 Episode Steps:     2 Return: -1.0000 FPS: 401.56\n",
      "15:53:06.707 [INFO] (irl_trainer.py:74) Total Epi:    58 Steps:     384 Episode Steps:    11 Return: -1.0000 FPS: 497.41\n",
      "15:53:06.717 [INFO] (irl_trainer.py:74) Total Epi:    59 Steps:     388 Episode Steps:     4 Return: -1.0000 FPS: 524.03\n",
      "15:53:06.725 [INFO] (irl_trainer.py:74) Total Epi:    60 Steps:     390 Episode Steps:     2 Return: -1.0000 FPS: 321.30\n",
      "15:53:06.755 [INFO] (irl_trainer.py:74) Total Epi:    61 Steps:     412 Episode Steps:    22 Return: -1.0000 FPS: 777.08\n",
      "15:53:06.769 [INFO] (irl_trainer.py:74) Total Epi:    62 Steps:     420 Episode Steps:     8 Return: -1.0000 FPS: 641.03\n",
      "15:53:06.853 [INFO] (irl_trainer.py:74) Total Epi:    63 Steps:     481 Episode Steps:    61 Return: -1.0000 FPS: 751.98\n",
      "15:53:06.865 [INFO] (irl_trainer.py:74) Total Epi:    64 Steps:     486 Episode Steps:     5 Return: -1.0000 FPS: 499.43\n",
      "15:53:06.881 [INFO] (irl_trainer.py:74) Total Epi:    65 Steps:     493 Episode Steps:     7 Return: -1.0000 FPS: 526.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:53:06.891 [INFO] (irl_trainer.py:74) Total Epi:    66 Steps:     495 Episode Steps:     2 Return: -1.0000 FPS: 288.65\n",
      "15:53:06.900 [INFO] (irl_trainer.py:74) Total Epi:    67 Steps:     499 Episode Steps:     4 Return: -1.0000 FPS: 571.71\n",
      "15:53:06.907 [INFO] (irl_trainer.py:74) Total Epi:    68 Steps:     502 Episode Steps:     3 Return: -1.0000 FPS: 504.48\n",
      "15:53:06.915 [INFO] (irl_trainer.py:74) Total Epi:    69 Steps:     505 Episode Steps:     3 Return: -1.0000 FPS: 486.81\n",
      "15:53:06.921 [INFO] (irl_trainer.py:74) Total Epi:    70 Steps:     507 Episode Steps:     2 Return: -1.0000 FPS: 401.08\n",
      "15:53:06.941 [INFO] (irl_trainer.py:74) Total Epi:    71 Steps:     518 Episode Steps:    11 Return: -1.0000 FPS: 589.68\n",
      "15:53:06.948 [INFO] (irl_trainer.py:74) Total Epi:    72 Steps:     520 Episode Steps:     2 Return: -1.0000 FPS: 409.61\n",
      "15:53:06.960 [INFO] (irl_trainer.py:74) Total Epi:    73 Steps:     527 Episode Steps:     7 Return: -1.0000 FPS: 662.10\n",
      "15:53:06.984 [INFO] (irl_trainer.py:74) Total Epi:    74 Steps:     544 Episode Steps:    17 Return:  1.0000 FPS: 757.19\n",
      "15:53:06.990 [INFO] (irl_trainer.py:74) Total Epi:    75 Steps:     546 Episode Steps:     2 Return: -1.0000 FPS: 412.25\n",
      "15:53:07.009 [INFO] (irl_trainer.py:74) Total Epi:    76 Steps:     556 Episode Steps:    10 Return: -1.0000 FPS: 576.32\n",
      "15:53:07.020 [INFO] (irl_trainer.py:74) Total Epi:    77 Steps:     561 Episode Steps:     5 Return: -1.0000 FPS: 553.04\n",
      "15:53:07.031 [INFO] (irl_trainer.py:74) Total Epi:    78 Steps:     564 Episode Steps:     3 Return: -1.0000 FPS: 319.41\n",
      "15:53:07.041 [INFO] (irl_trainer.py:74) Total Epi:    79 Steps:     568 Episode Steps:     4 Return: -1.0000 FPS: 539.87\n",
      "15:53:07.048 [INFO] (irl_trainer.py:74) Total Epi:    80 Steps:     571 Episode Steps:     3 Return: -1.0000 FPS: 485.88\n",
      "15:53:07.054 [INFO] (irl_trainer.py:74) Total Epi:    81 Steps:     573 Episode Steps:     2 Return: -1.0000 FPS: 419.52\n",
      "15:53:07.084 [INFO] (irl_trainer.py:74) Total Epi:    82 Steps:     593 Episode Steps:    20 Return: -1.0000 FPS: 709.36\n",
      "15:53:07.117 [INFO] (irl_trainer.py:74) Total Epi:    83 Steps:     614 Episode Steps:    21 Return: -1.0000 FPS: 682.86\n",
      "15:53:07.125 [INFO] (irl_trainer.py:74) Total Epi:    84 Steps:     617 Episode Steps:     3 Return: -1.0000 FPS: 436.22\n",
      "15:53:07.133 [INFO] (irl_trainer.py:74) Total Epi:    85 Steps:     620 Episode Steps:     3 Return: -1.0000 FPS: 464.30\n",
      "15:53:07.142 [INFO] (irl_trainer.py:74) Total Epi:    86 Steps:     624 Episode Steps:     4 Return: -1.0000 FPS: 559.98\n",
      "15:53:07.150 [INFO] (irl_trainer.py:74) Total Epi:    87 Steps:     627 Episode Steps:     3 Return: -1.0000 FPS: 469.75\n",
      "15:53:07.165 [INFO] (irl_trainer.py:74) Total Epi:    88 Steps:     636 Episode Steps:     9 Return: -1.0000 FPS: 677.05\n",
      "15:53:07.191 [INFO] (irl_trainer.py:74) Total Epi:    89 Steps:     652 Episode Steps:    16 Return: -1.0000 FPS: 662.88\n",
      "15:53:07.201 [INFO] (irl_trainer.py:74) Total Epi:    90 Steps:     657 Episode Steps:     5 Return: -1.0000 FPS: 619.44\n",
      "15:53:07.224 [INFO] (irl_trainer.py:74) Total Epi:    91 Steps:     673 Episode Steps:    16 Return: -1.0000 FPS: 725.80\n",
      "15:53:07.242 [INFO] (irl_trainer.py:74) Total Epi:    92 Steps:     684 Episode Steps:    11 Return: -1.0000 FPS: 663.54\n",
      "15:53:07.249 [INFO] (irl_trainer.py:74) Total Epi:    93 Steps:     686 Episode Steps:     2 Return: -1.0000 FPS: 356.37\n",
      "15:53:07.263 [INFO] (irl_trainer.py:74) Total Epi:    94 Steps:     693 Episode Steps:     7 Return: -1.0000 FPS: 610.30\n",
      "15:53:07.273 [INFO] (irl_trainer.py:74) Total Epi:    95 Steps:     697 Episode Steps:     4 Return: -1.0000 FPS: 550.42\n",
      "15:53:07.282 [INFO] (irl_trainer.py:74) Total Epi:    96 Steps:     702 Episode Steps:     5 Return: -1.0000 FPS: 599.42\n",
      "15:53:07.293 [INFO] (irl_trainer.py:74) Total Epi:    97 Steps:     708 Episode Steps:     6 Return: -1.0000 FPS: 636.12\n",
      "15:53:07.301 [INFO] (irl_trainer.py:74) Total Epi:    98 Steps:     710 Episode Steps:     2 Return: -1.0000 FPS: 334.25\n",
      "15:53:07.309 [INFO] (irl_trainer.py:74) Total Epi:    99 Steps:     713 Episode Steps:     3 Return: -1.0000 FPS: 505.55\n",
      "15:53:07.329 [INFO] (irl_trainer.py:74) Total Epi:   100 Steps:     728 Episode Steps:    15 Return: -1.0000 FPS: 770.67\n",
      "15:53:07.353 [INFO] (irl_trainer.py:74) Total Epi:   101 Steps:     743 Episode Steps:    15 Return: -1.0000 FPS: 718.22\n",
      "15:53:07.362 [INFO] (irl_trainer.py:74) Total Epi:   102 Steps:     747 Episode Steps:     4 Return: -1.0000 FPS: 531.39\n",
      "15:53:07.369 [INFO] (irl_trainer.py:74) Total Epi:   103 Steps:     749 Episode Steps:     2 Return: -1.0000 FPS: 377.71\n",
      "15:53:07.386 [INFO] (irl_trainer.py:74) Total Epi:   104 Steps:     760 Episode Steps:    11 Return: -1.0000 FPS: 694.40\n",
      "15:53:07.396 [INFO] (irl_trainer.py:74) Total Epi:   105 Steps:     765 Episode Steps:     5 Return: -1.0000 FPS: 596.18\n",
      "15:53:07.404 [INFO] (irl_trainer.py:74) Total Epi:   106 Steps:     768 Episode Steps:     3 Return: -1.0000 FPS: 486.16\n",
      "15:53:07.414 [INFO] (irl_trainer.py:74) Total Epi:   107 Steps:     773 Episode Steps:     5 Return: -1.0000 FPS: 604.59\n",
      "15:53:07.423 [INFO] (irl_trainer.py:74) Total Epi:   108 Steps:     776 Episode Steps:     3 Return: -1.0000 FPS: 415.47\n",
      "15:53:07.434 [INFO] (irl_trainer.py:74) Total Epi:   109 Steps:     782 Episode Steps:     6 Return: -1.0000 FPS: 611.35\n",
      "15:53:07.444 [INFO] (irl_trainer.py:74) Total Epi:   110 Steps:     787 Episode Steps:     5 Return: -1.0000 FPS: 580.61\n",
      "15:53:07.461 [INFO] (irl_trainer.py:74) Total Epi:   111 Steps:     797 Episode Steps:    10 Return: -1.0000 FPS: 646.77\n",
      "15:53:07.469 [INFO] (irl_trainer.py:74) Total Epi:   112 Steps:     800 Episode Steps:     3 Return: -1.0000 FPS: 476.97\n",
      "15:53:07.476 [INFO] (irl_trainer.py:74) Total Epi:   113 Steps:     802 Episode Steps:     2 Return: -1.0000 FPS: 392.52\n",
      "15:53:07.483 [INFO] (irl_trainer.py:74) Total Epi:   114 Steps:     805 Episode Steps:     3 Return: -1.0000 FPS: 496.71\n",
      "15:53:07.489 [INFO] (irl_trainer.py:74) Total Epi:   115 Steps:     807 Episode Steps:     2 Return: -1.0000 FPS: 400.26\n",
      "15:53:07.511 [INFO] (irl_trainer.py:74) Total Epi:   116 Steps:     822 Episode Steps:    15 Return: -1.0000 FPS: 723.43\n",
      "15:53:07.521 [INFO] (irl_trainer.py:74) Total Epi:   117 Steps:     825 Episode Steps:     3 Return: -1.0000 FPS: 486.60\n",
      "15:53:07.529 [INFO] (irl_trainer.py:74) Total Epi:   118 Steps:     829 Episode Steps:     4 Return: -1.0000 FPS: 582.11\n",
      "15:53:07.545 [INFO] (irl_trainer.py:74) Total Epi:   119 Steps:     839 Episode Steps:    10 Return: -1.0000 FPS: 693.99\n",
      "15:53:07.554 [INFO] (irl_trainer.py:74) Total Epi:   120 Steps:     843 Episode Steps:     4 Return: -1.0000 FPS: 542.25\n",
      "15:53:07.566 [INFO] (irl_trainer.py:74) Total Epi:   121 Steps:     849 Episode Steps:     6 Return: -1.0000 FPS: 564.80\n",
      "15:53:07.582 [INFO] (irl_trainer.py:74) Total Epi:   122 Steps:     859 Episode Steps:    10 Return: -1.0000 FPS: 704.38\n",
      "15:53:07.590 [INFO] (irl_trainer.py:74) Total Epi:   123 Steps:     862 Episode Steps:     3 Return: -1.0000 FPS: 487.79\n",
      "15:53:07.615 [INFO] (irl_trainer.py:74) Total Epi:   124 Steps:     879 Episode Steps:    17 Return: -1.0000 FPS: 724.24\n",
      "15:53:07.622 [INFO] (irl_trainer.py:74) Total Epi:   125 Steps:     881 Episode Steps:     2 Return: -1.0000 FPS: 388.59\n",
      "15:53:07.629 [INFO] (irl_trainer.py:74) Total Epi:   126 Steps:     883 Episode Steps:     2 Return: -1.0000 FPS: 367.75\n",
      "15:53:07.641 [INFO] (irl_trainer.py:74) Total Epi:   127 Steps:     889 Episode Steps:     6 Return: -1.0000 FPS: 611.01\n",
      "15:53:07.669 [INFO] (irl_trainer.py:74) Total Epi:   128 Steps:     907 Episode Steps:    18 Return: -1.0000 FPS: 700.88\n",
      "15:53:07.676 [INFO] (irl_trainer.py:74) Total Epi:   129 Steps:     910 Episode Steps:     3 Return: -1.0000 FPS: 508.78\n",
      "15:53:07.685 [INFO] (irl_trainer.py:74) Total Epi:   130 Steps:     914 Episode Steps:     4 Return: -1.0000 FPS: 540.52\n",
      "15:53:07.700 [INFO] (irl_trainer.py:74) Total Epi:   131 Steps:     922 Episode Steps:     8 Return: -1.0000 FPS: 636.77\n",
      "15:53:07.710 [INFO] (irl_trainer.py:74) Total Epi:   132 Steps:     927 Episode Steps:     5 Return: -1.0000 FPS: 601.43\n",
      "15:53:07.719 [INFO] (irl_trainer.py:74) Total Epi:   133 Steps:     930 Episode Steps:     3 Return: -1.0000 FPS: 439.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:53:07.726 [INFO] (irl_trainer.py:74) Total Epi:   134 Steps:     933 Episode Steps:     3 Return: -1.0000 FPS: 487.34\n",
      "15:53:07.735 [INFO] (irl_trainer.py:74) Total Epi:   135 Steps:     937 Episode Steps:     4 Return: -1.0000 FPS: 574.73\n",
      "15:53:07.742 [INFO] (irl_trainer.py:74) Total Epi:   136 Steps:     940 Episode Steps:     3 Return: -1.0000 FPS: 514.37\n",
      "15:53:07.750 [INFO] (irl_trainer.py:74) Total Epi:   137 Steps:     944 Episode Steps:     4 Return: -1.0000 FPS: 550.08\n",
      "15:53:07.757 [INFO] (irl_trainer.py:74) Total Epi:   138 Steps:     947 Episode Steps:     3 Return: -1.0000 FPS: 509.77\n",
      "15:53:07.779 [INFO] (irl_trainer.py:74) Total Epi:   139 Steps:     962 Episode Steps:    15 Return: -1.0000 FPS: 750.04\n",
      "15:53:07.788 [INFO] (irl_trainer.py:74) Total Epi:   140 Steps:     966 Episode Steps:     4 Return: -1.0000 FPS: 543.40\n",
      "15:53:07.824 [INFO] (irl_trainer.py:74) Total Epi:   141 Steps:     991 Episode Steps:    25 Return: -1.0000 FPS: 735.29\n",
      "15:53:07.833 [INFO] (irl_trainer.py:74) Total Epi:   142 Steps:     995 Episode Steps:     4 Return: -1.0000 FPS: 546.92\n",
      "15:53:07.843 [INFO] (irl_trainer.py:74) Total Epi:   143 Steps:     999 Episode Steps:     4 Return: -1.0000 FPS: 467.75\n",
      "15:53:10.872 [INFO] (irl_trainer.py:119) Evaluation Total Steps:    1000 Average Reward -1.0000 / Average Step Count  10.2 over  5 episodes\n",
      "15:53:10.908 [INFO] (irl_trainer.py:74) Total Epi:   144 Steps:    1001 Episode Steps:     2 Return: -1.0000 FPS:  0.65\n",
      "15:53:11.219 [INFO] (irl_trainer.py:74) Total Epi:   145 Steps:    1015 Episode Steps:    14 Return: -1.0000 FPS: 45.24\n",
      "15:53:11.310 [INFO] (irl_trainer.py:74) Total Epi:   146 Steps:    1020 Episode Steps:     5 Return: -1.0000 FPS: 56.09\n",
      "15:53:11.367 [INFO] (irl_trainer.py:74) Total Epi:   147 Steps:    1023 Episode Steps:     3 Return: -1.0000 FPS: 53.99\n",
      "15:53:11.441 [INFO] (irl_trainer.py:74) Total Epi:   148 Steps:    1027 Episode Steps:     4 Return: -1.0000 FPS: 55.44\n",
      "15:53:11.509 [INFO] (irl_trainer.py:74) Total Epi:   149 Steps:    1031 Episode Steps:     4 Return: -1.0000 FPS: 60.50\n",
      "15:53:12.125 [INFO] (irl_trainer.py:74) Total Epi:   150 Steps:    1070 Episode Steps:    39 Return: -1.0000 FPS: 63.47\n",
      "15:53:12.192 [INFO] (irl_trainer.py:74) Total Epi:   151 Steps:    1074 Episode Steps:     4 Return: -1.0000 FPS: 61.31\n",
      "15:53:12.245 [INFO] (irl_trainer.py:74) Total Epi:   152 Steps:    1077 Episode Steps:     3 Return: -1.0000 FPS: 58.60\n",
      "15:53:12.305 [INFO] (irl_trainer.py:74) Total Epi:   153 Steps:    1080 Episode Steps:     3 Return: -1.0000 FPS: 51.55\n",
      "15:53:12.365 [INFO] (irl_trainer.py:74) Total Epi:   154 Steps:    1083 Episode Steps:     3 Return: -1.0000 FPS: 52.47\n",
      "15:53:12.482 [INFO] (irl_trainer.py:74) Total Epi:   155 Steps:    1089 Episode Steps:     6 Return: -1.0000 FPS: 52.20\n",
      "15:53:12.536 [INFO] (irl_trainer.py:74) Total Epi:   156 Steps:    1092 Episode Steps:     3 Return: -1.0000 FPS: 57.03\n",
      "15:53:12.617 [INFO] (irl_trainer.py:74) Total Epi:   157 Steps:    1095 Episode Steps:     3 Return: -1.0000 FPS: 37.77\n",
      "15:53:12.808 [INFO] (irl_trainer.py:74) Total Epi:   158 Steps:    1106 Episode Steps:    11 Return: -1.0000 FPS: 58.22\n",
      "15:53:12.863 [INFO] (irl_trainer.py:74) Total Epi:   159 Steps:    1109 Episode Steps:     3 Return: -1.0000 FPS: 56.59\n",
      "15:53:12.913 [INFO] (irl_trainer.py:74) Total Epi:   160 Steps:    1112 Episode Steps:     3 Return: -1.0000 FPS: 62.38\n",
      "15:53:13.013 [INFO] (irl_trainer.py:74) Total Epi:   161 Steps:    1118 Episode Steps:     6 Return: -1.0000 FPS: 60.88\n",
      "15:53:13.105 [INFO] (irl_trainer.py:74) Total Epi:   162 Steps:    1123 Episode Steps:     5 Return: -1.0000 FPS: 55.15\n",
      "15:53:13.167 [INFO] (irl_trainer.py:74) Total Epi:   163 Steps:    1126 Episode Steps:     3 Return: -1.0000 FPS: 50.20\n",
      "15:53:13.231 [INFO] (irl_trainer.py:74) Total Epi:   164 Steps:    1129 Episode Steps:     3 Return: -1.0000 FPS: 47.84\n",
      "15:53:13.287 [INFO] (irl_trainer.py:74) Total Epi:   165 Steps:    1132 Episode Steps:     3 Return: -1.0000 FPS: 55.47\n",
      "15:53:13.329 [INFO] (irl_trainer.py:74) Total Epi:   166 Steps:    1134 Episode Steps:     2 Return: -1.0000 FPS: 49.60\n",
      "15:53:13.386 [INFO] (irl_trainer.py:74) Total Epi:   167 Steps:    1136 Episode Steps:     2 Return: -1.0000 FPS: 36.08\n",
      "15:53:13.470 [INFO] (irl_trainer.py:74) Total Epi:   168 Steps:    1139 Episode Steps:     3 Return: -1.0000 FPS: 37.83\n",
      "15:53:13.600 [INFO] (irl_trainer.py:74) Total Epi:   169 Steps:    1144 Episode Steps:     5 Return: -1.0000 FPS: 39.43\n",
      "15:53:13.738 [INFO] (irl_trainer.py:74) Total Epi:   170 Steps:    1150 Episode Steps:     6 Return: -1.0000 FPS: 43.99\n",
      "15:53:13.826 [INFO] (irl_trainer.py:74) Total Epi:   171 Steps:    1155 Episode Steps:     5 Return: -1.0000 FPS: 59.09\n",
      "15:53:13.876 [INFO] (irl_trainer.py:74) Total Epi:   172 Steps:    1158 Episode Steps:     3 Return: -1.0000 FPS: 61.79\n",
      "15:53:13.948 [INFO] (irl_trainer.py:74) Total Epi:   173 Steps:    1162 Episode Steps:     4 Return: -1.0000 FPS: 56.54\n",
      "15:53:14.213 [INFO] (irl_trainer.py:74) Total Epi:   174 Steps:    1174 Episode Steps:    12 Return: -1.0000 FPS: 45.77\n",
      "15:53:14.385 [INFO] (irl_trainer.py:74) Total Epi:   175 Steps:    1185 Episode Steps:    11 Return: -1.0000 FPS: 64.61\n",
      "15:53:14.438 [INFO] (irl_trainer.py:74) Total Epi:   176 Steps:    1188 Episode Steps:     3 Return: -1.0000 FPS: 58.28\n",
      "15:53:14.505 [INFO] (irl_trainer.py:74) Total Epi:   177 Steps:    1192 Episode Steps:     4 Return: -1.0000 FPS: 61.13\n",
      "15:53:14.635 [INFO] (irl_trainer.py:74) Total Epi:   178 Steps:    1200 Episode Steps:     8 Return: -1.0000 FPS: 61.98\n",
      "15:53:14.778 [INFO] (irl_trainer.py:74) Total Epi:   179 Steps:    1209 Episode Steps:     9 Return: -1.0000 FPS: 63.57\n",
      "15:53:14.968 [INFO] (irl_trainer.py:74) Total Epi:   180 Steps:    1221 Episode Steps:    12 Return: -1.0000 FPS: 63.70\n",
      "15:53:15.034 [INFO] (irl_trainer.py:74) Total Epi:   181 Steps:    1225 Episode Steps:     4 Return: -1.0000 FPS: 62.85\n",
      "15:53:15.121 [INFO] (irl_trainer.py:74) Total Epi:   182 Steps:    1230 Episode Steps:     5 Return: -1.0000 FPS: 57.88\n",
      "15:53:15.477 [INFO] (irl_trainer.py:74) Total Epi:   183 Steps:    1253 Episode Steps:    23 Return: -1.0000 FPS: 65.00\n",
      "15:53:15.573 [INFO] (irl_trainer.py:74) Total Epi:   184 Steps:    1259 Episode Steps:     6 Return: -1.0000 FPS: 63.65\n",
      "15:53:15.625 [INFO] (irl_trainer.py:74) Total Epi:   185 Steps:    1262 Episode Steps:     3 Return: -1.0000 FPS: 58.88\n",
      "15:53:15.840 [INFO] (irl_trainer.py:74) Total Epi:   186 Steps:    1276 Episode Steps:    14 Return: -1.0000 FPS: 65.58\n",
      "15:53:16.279 [INFO] (irl_trainer.py:74) Total Epi:   187 Steps:    1305 Episode Steps:    29 Return: -1.0000 FPS: 66.18\n",
      "15:53:16.454 [INFO] (irl_trainer.py:74) Total Epi:   188 Steps:    1316 Episode Steps:    11 Return: -1.0000 FPS: 63.75\n",
      "15:53:16.562 [INFO] (irl_trainer.py:74) Total Epi:   189 Steps:    1323 Episode Steps:     7 Return: -1.0000 FPS: 65.84\n",
      "15:53:16.644 [INFO] (irl_trainer.py:74) Total Epi:   190 Steps:    1328 Episode Steps:     5 Return: -1.0000 FPS: 62.29\n",
      "15:53:16.901 [INFO] (irl_trainer.py:74) Total Epi:   191 Steps:    1345 Episode Steps:    17 Return:  1.0000 FPS: 66.47\n",
      "15:53:16.995 [INFO] (irl_trainer.py:74) Total Epi:   192 Steps:    1351 Episode Steps:     6 Return: -1.0000 FPS: 64.63\n",
      "15:53:17.286 [INFO] (irl_trainer.py:74) Total Epi:   193 Steps:    1370 Episode Steps:    19 Return: -1.0000 FPS: 66.01\n",
      "15:53:17.352 [INFO] (irl_trainer.py:74) Total Epi:   194 Steps:    1374 Episode Steps:     4 Return: -1.0000 FPS: 61.90\n",
      "15:53:17.449 [INFO] (irl_trainer.py:74) Total Epi:   195 Steps:    1380 Episode Steps:     6 Return: -1.0000 FPS: 63.27\n",
      "15:53:17.642 [INFO] (irl_trainer.py:74) Total Epi:   196 Steps:    1392 Episode Steps:    12 Return: -1.0000 FPS: 62.47\n",
      "15:53:17.877 [INFO] (irl_trainer.py:74) Total Epi:   197 Steps:    1407 Episode Steps:    15 Return: -1.0000 FPS: 64.28\n",
      "15:53:18.129 [INFO] (irl_trainer.py:74) Total Epi:   198 Steps:    1423 Episode Steps:    16 Return: -1.0000 FPS: 64.01\n",
      "15:53:18.528 [INFO] (irl_trainer.py:74) Total Epi:   199 Steps:    1449 Episode Steps:    26 Return: -1.0000 FPS: 65.37\n",
      "15:53:18.775 [INFO] (irl_trainer.py:74) Total Epi:   200 Steps:    1465 Episode Steps:    16 Return: -1.0000 FPS: 65.14\n",
      "15:53:19.020 [INFO] (irl_trainer.py:74) Total Epi:   201 Steps:    1481 Episode Steps:    16 Return: -1.0000 FPS: 65.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:53:19.281 [INFO] (irl_trainer.py:74) Total Epi:   202 Steps:    1497 Episode Steps:    16 Return: -1.0000 FPS: 61.68\n",
      "15:53:19.489 [INFO] (irl_trainer.py:74) Total Epi:   203 Steps:    1508 Episode Steps:    11 Return: -1.0000 FPS: 53.47\n",
      "15:53:19.899 [INFO] (irl_trainer.py:74) Total Epi:   204 Steps:    1532 Episode Steps:    24 Return: -1.0000 FPS: 58.75\n",
      "15:53:20.278 [INFO] (irl_trainer.py:74) Total Epi:   205 Steps:    1555 Episode Steps:    23 Return: -1.0000 FPS: 60.96\n",
      "15:53:20.630 [INFO] (irl_trainer.py:74) Total Epi:   206 Steps:    1577 Episode Steps:    22 Return:  1.0000 FPS: 62.68\n",
      "15:53:20.804 [INFO] (irl_trainer.py:74) Total Epi:   207 Steps:    1588 Episode Steps:    11 Return: -1.0000 FPS: 63.64\n",
      "15:53:21.169 [INFO] (irl_trainer.py:74) Total Epi:   208 Steps:    1608 Episode Steps:    20 Return: -1.0000 FPS: 54.99\n",
      "15:53:21.327 [INFO] (irl_trainer.py:74) Total Epi:   209 Steps:    1618 Episode Steps:    10 Return: -1.0000 FPS: 63.87\n",
      "15:53:21.555 [INFO] (irl_trainer.py:74) Total Epi:   210 Steps:    1632 Episode Steps:    14 Return: -1.0000 FPS: 62.06\n",
      "15:53:21.873 [INFO] (irl_trainer.py:74) Total Epi:   211 Steps:    1651 Episode Steps:    19 Return: -1.0000 FPS: 60.05\n",
      "15:53:22.074 [INFO] (irl_trainer.py:74) Total Epi:   212 Steps:    1663 Episode Steps:    12 Return: -1.0000 FPS: 60.53\n",
      "15:53:22.248 [INFO] (irl_trainer.py:74) Total Epi:   213 Steps:    1674 Episode Steps:    11 Return: -1.0000 FPS: 63.79\n",
      "15:53:22.648 [INFO] (irl_trainer.py:74) Total Epi:   214 Steps:    1692 Episode Steps:    18 Return: -1.0000 FPS: 45.18\n",
      "15:53:22.850 [INFO] (irl_trainer.py:74) Total Epi:   215 Steps:    1705 Episode Steps:    13 Return: -1.0000 FPS: 64.62\n",
      "15:53:22.934 [INFO] (irl_trainer.py:74) Total Epi:   216 Steps:    1710 Episode Steps:     5 Return: -1.0000 FPS: 60.85\n",
      "15:53:23.086 [INFO] (irl_trainer.py:74) Total Epi:   217 Steps:    1719 Episode Steps:     9 Return: -1.0000 FPS: 59.96\n",
      "15:53:23.189 [INFO] (irl_trainer.py:74) Total Epi:   218 Steps:    1725 Episode Steps:     6 Return: -1.0000 FPS: 59.12\n",
      "15:53:23.401 [INFO] (irl_trainer.py:74) Total Epi:   219 Steps:    1738 Episode Steps:    13 Return:  1.0000 FPS: 61.89\n",
      "15:53:23.580 [INFO] (irl_trainer.py:74) Total Epi:   220 Steps:    1749 Episode Steps:    11 Return: -1.0000 FPS: 62.06\n",
      "15:53:23.757 [INFO] (irl_trainer.py:74) Total Epi:   221 Steps:    1760 Episode Steps:    11 Return: -1.0000 FPS: 62.56\n",
      "15:53:23.862 [INFO] (irl_trainer.py:74) Total Epi:   222 Steps:    1766 Episode Steps:     6 Return: -1.0000 FPS: 58.02\n",
      "15:53:24.037 [INFO] (irl_trainer.py:74) Total Epi:   223 Steps:    1777 Episode Steps:    11 Return: -1.0000 FPS: 63.91\n",
      "15:53:24.328 [INFO] (irl_trainer.py:74) Total Epi:   224 Steps:    1793 Episode Steps:    16 Return: -1.0000 FPS: 55.26\n",
      "15:53:24.402 [INFO] (irl_trainer.py:74) Total Epi:   225 Steps:    1797 Episode Steps:     4 Return: -1.0000 FPS: 55.49\n",
      "15:53:24.588 [INFO] (irl_trainer.py:74) Total Epi:   226 Steps:    1809 Episode Steps:    12 Return: -1.0000 FPS: 65.27\n",
      "15:53:24.799 [INFO] (irl_trainer.py:74) Total Epi:   227 Steps:    1822 Episode Steps:    13 Return: -1.0000 FPS: 62.48\n",
      "15:53:25.060 [INFO] (irl_trainer.py:74) Total Epi:   228 Steps:    1837 Episode Steps:    15 Return: -1.0000 FPS: 57.84\n",
      "15:53:25.142 [INFO] (irl_trainer.py:74) Total Epi:   229 Steps:    1842 Episode Steps:     5 Return: -1.0000 FPS: 62.16\n",
      "15:53:25.413 [INFO] (irl_trainer.py:74) Total Epi:   230 Steps:    1853 Episode Steps:    11 Return: -1.0000 FPS: 40.93\n",
      "15:53:25.674 [INFO] (irl_trainer.py:74) Total Epi:   231 Steps:    1868 Episode Steps:    15 Return: -1.0000 FPS: 57.79\n",
      "15:53:25.805 [INFO] (irl_trainer.py:74) Total Epi:   232 Steps:    1876 Episode Steps:     8 Return: -1.0000 FPS: 61.89\n",
      "15:53:25.997 [INFO] (irl_trainer.py:74) Total Epi:   233 Steps:    1888 Episode Steps:    12 Return: -1.0000 FPS: 63.28\n",
      "15:53:26.241 [INFO] (irl_trainer.py:74) Total Epi:   234 Steps:    1904 Episode Steps:    16 Return: -1.0000 FPS: 65.82\n",
      "15:53:26.437 [INFO] (irl_trainer.py:74) Total Epi:   235 Steps:    1916 Episode Steps:    12 Return: -1.0000 FPS: 61.67\n",
      "15:53:26.675 [INFO] (irl_trainer.py:74) Total Epi:   236 Steps:    1931 Episode Steps:    15 Return: -1.0000 FPS: 63.59\n",
      "15:53:26.982 [INFO] (irl_trainer.py:74) Total Epi:   237 Steps:    1951 Episode Steps:    20 Return: -1.0000 FPS: 65.39\n",
      "15:53:27.301 [INFO] (irl_trainer.py:74) Total Epi:   238 Steps:    1965 Episode Steps:    14 Return: -1.0000 FPS: 44.13\n",
      "15:53:27.462 [INFO] (irl_trainer.py:74) Total Epi:   239 Steps:    1972 Episode Steps:     7 Return: -1.0000 FPS: 44.13\n",
      "15:53:27.669 [INFO] (irl_trainer.py:74) Total Epi:   240 Steps:    1985 Episode Steps:    13 Return: -1.0000 FPS: 63.71\n",
      "15:53:27.861 [INFO] (irl_trainer.py:74) Total Epi:   241 Steps:    1997 Episode Steps:    12 Return: -1.0000 FPS: 62.73\n",
      "15:53:28.007 [INFO] (irl_trainer.py:119) Evaluation Total Steps:    2000 Average Reward -1.0000 / Average Step Count  7.6 over  5 episodes\n",
      "15:53:28.017 [INFO] (irl_trainer.py:74) Total Epi:   242 Steps:    2001 Episode Steps:     4 Return: -1.0000 FPS: 26.06\n",
      "15:53:28.213 [INFO] (irl_trainer.py:74) Total Epi:   243 Steps:    2013 Episode Steps:    12 Return: -1.0000 FPS: 62.17\n",
      "15:53:28.405 [INFO] (irl_trainer.py:74) Total Epi:   244 Steps:    2025 Episode Steps:    12 Return: -1.0000 FPS: 62.93\n",
      "15:53:28.687 [INFO] (irl_trainer.py:74) Total Epi:   245 Steps:    2043 Episode Steps:    18 Return: -1.0000 FPS: 64.14\n",
      "15:53:28.832 [INFO] (irl_trainer.py:74) Total Epi:   246 Steps:    2049 Episode Steps:     6 Return: -1.0000 FPS: 41.98\n",
      "15:53:29.011 [INFO] (irl_trainer.py:74) Total Epi:   247 Steps:    2059 Episode Steps:    10 Return: -1.0000 FPS: 56.48\n",
      "15:53:29.091 [INFO] (irl_trainer.py:74) Total Epi:   248 Steps:    2064 Episode Steps:     5 Return: -1.0000 FPS: 63.19\n",
      "15:53:29.282 [INFO] (irl_trainer.py:74) Total Epi:   249 Steps:    2076 Episode Steps:    12 Return: -1.0000 FPS: 63.43\n",
      "15:53:29.413 [INFO] (irl_trainer.py:74) Total Epi:   250 Steps:    2084 Episode Steps:     8 Return: -1.0000 FPS: 61.53\n",
      "15:53:29.646 [INFO] (irl_trainer.py:74) Total Epi:   251 Steps:    2099 Episode Steps:    15 Return: -1.0000 FPS: 64.96\n",
      "15:53:29.804 [INFO] (irl_trainer.py:74) Total Epi:   252 Steps:    2109 Episode Steps:    10 Return: -1.0000 FPS: 64.01\n",
      "15:53:29.939 [INFO] (irl_trainer.py:74) Total Epi:   253 Steps:    2117 Episode Steps:     8 Return: -1.0000 FPS: 59.86\n",
      "15:53:30.174 [INFO] (irl_trainer.py:74) Total Epi:   254 Steps:    2132 Episode Steps:    15 Return: -1.0000 FPS: 64.20\n",
      "15:53:30.374 [INFO] (irl_trainer.py:74) Total Epi:   255 Steps:    2144 Episode Steps:    12 Return: -1.0000 FPS: 60.41\n",
      "15:53:30.502 [INFO] (irl_trainer.py:74) Total Epi:   256 Steps:    2151 Episode Steps:     7 Return: -1.0000 FPS: 55.75\n",
      "15:53:30.698 [INFO] (irl_trainer.py:74) Total Epi:   257 Steps:    2163 Episode Steps:    12 Return: -1.0000 FPS: 61.42\n",
      "15:53:30.940 [INFO] (irl_trainer.py:74) Total Epi:   258 Steps:    2177 Episode Steps:    14 Return: -1.0000 FPS: 58.36\n",
      "15:53:31.040 [INFO] (irl_trainer.py:74) Total Epi:   259 Steps:    2183 Episode Steps:     6 Return: -1.0000 FPS: 61.08\n",
      "15:53:31.218 [INFO] (irl_trainer.py:74) Total Epi:   260 Steps:    2194 Episode Steps:    11 Return: -1.0000 FPS: 62.19\n",
      "15:53:31.303 [INFO] (irl_trainer.py:74) Total Epi:   261 Steps:    2199 Episode Steps:     5 Return: -1.0000 FPS: 60.24\n",
      "15:53:31.387 [INFO] (irl_trainer.py:74) Total Epi:   262 Steps:    2204 Episode Steps:     5 Return: -1.0000 FPS: 60.22\n",
      "15:53:31.545 [INFO] (irl_trainer.py:74) Total Epi:   263 Steps:    2214 Episode Steps:    10 Return: -1.0000 FPS: 64.16\n",
      "15:53:31.709 [INFO] (irl_trainer.py:74) Total Epi:   264 Steps:    2224 Episode Steps:    10 Return: -1.0000 FPS: 61.41\n",
      "15:53:31.779 [INFO] (irl_trainer.py:74) Total Epi:   265 Steps:    2228 Episode Steps:     4 Return: -1.0000 FPS: 58.39\n",
      "15:53:32.046 [INFO] (irl_trainer.py:74) Total Epi:   266 Steps:    2245 Episode Steps:    17 Return:  1.0000 FPS: 63.93\n",
      "15:53:32.235 [INFO] (irl_trainer.py:74) Total Epi:   267 Steps:    2257 Episode Steps:    12 Return: -1.0000 FPS: 64.22\n",
      "15:53:32.372 [INFO] (irl_trainer.py:74) Total Epi:   268 Steps:    2265 Episode Steps:     8 Return: -1.0000 FPS: 58.97\n",
      "15:53:32.459 [INFO] (irl_trainer.py:74) Total Epi:   269 Steps:    2270 Episode Steps:     5 Return: -1.0000 FPS: 58.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:53:32.540 [INFO] (irl_trainer.py:74) Total Epi:   270 Steps:    2275 Episode Steps:     5 Return: -1.0000 FPS: 63.03\n",
      "15:53:32.639 [INFO] (irl_trainer.py:74) Total Epi:   271 Steps:    2281 Episode Steps:     6 Return: -1.0000 FPS: 61.56\n",
      "15:53:32.790 [INFO] (irl_trainer.py:74) Total Epi:   272 Steps:    2290 Episode Steps:     9 Return: -1.0000 FPS: 60.37\n",
      "15:53:32.880 [INFO] (irl_trainer.py:74) Total Epi:   273 Steps:    2295 Episode Steps:     5 Return: -1.0000 FPS: 56.65\n",
      "15:53:33.071 [INFO] (irl_trainer.py:74) Total Epi:   274 Steps:    2305 Episode Steps:    10 Return: -1.0000 FPS: 52.76\n",
      "15:53:33.330 [INFO] (irl_trainer.py:74) Total Epi:   275 Steps:    2320 Episode Steps:    15 Return: -1.0000 FPS: 58.42\n",
      "15:53:33.522 [INFO] (irl_trainer.py:74) Total Epi:   276 Steps:    2331 Episode Steps:    11 Return: -1.0000 FPS: 57.70\n",
      "15:53:33.845 [INFO] (irl_trainer.py:74) Total Epi:   277 Steps:    2351 Episode Steps:    20 Return:  1.0000 FPS: 62.25\n",
      "15:53:33.994 [INFO] (irl_trainer.py:74) Total Epi:   278 Steps:    2360 Episode Steps:     9 Return: -1.0000 FPS: 61.18\n",
      "15:53:34.132 [INFO] (irl_trainer.py:74) Total Epi:   279 Steps:    2369 Episode Steps:     9 Return: -1.0000 FPS: 65.78\n",
      "15:53:34.246 [INFO] (irl_trainer.py:74) Total Epi:   280 Steps:    2376 Episode Steps:     7 Return: -1.0000 FPS: 62.33\n",
      "15:53:34.408 [INFO] (irl_trainer.py:74) Total Epi:   281 Steps:    2386 Episode Steps:    10 Return: -1.0000 FPS: 62.37\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7690b7b21209>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# train the agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.cache/bazel/_bazel_ferenc/d27c94d45ef586b197c709d8101d6384/execroot/bark_ml/bazel-out/k8-fastbuild/bin/docs/report/run.runfiles/bark_ml/bark_ml/library_wrappers/lib_tf2rl/runners/tf2rl_runner.py\u001b[0m in \u001b[0;36mTrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;34m\"\"\"trains the agent.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/bazel/_bazel_ferenc/d27c94d45ef586b197c709d8101d6384/execroot/bark_ml/bazel-out/k8-fastbuild/bin/docs/report/run.runfiles/bark_ml/bark_ml/library_wrappers/lib_tf2rl/runners/gail_runner.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0minstantiated\u001b[0m \u001b[0mby\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \"\"\"\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/bazel/_bazel_ferenc/d27c94d45ef586b197c709d8101d6384/execroot/bark_ml/bazel-out/k8-fastbuild/bin/docs/report/run.runfiles/com_github_keiohta_tf2rl/tf2rl/experiments/irl_trainer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     91\u001b[0m                             \u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"obs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"act\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"next_obs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                             \u001b[0mrew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"done\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                             None if not self._use_prioritized_rb else samples[\"weights\"])\n\u001b[0m\u001b[1;32m     94\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_prioritized_rb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                             td_error = self._policy.compute_td_error(\n",
      "\u001b[0;32m~/.cache/bazel/_bazel_ferenc/d27c94d45ef586b197c709d8101d6384/execroot/bark_ml/bazel-out/k8-fastbuild/bin/docs/report/run.runfiles/com_github_keiohta_tf2rl/tf2rl/algos/ddpg.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, states, actions, next_states, rewards, done, weights)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mactor_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             tf.summary.scalar(name=self.policy_name+\"/actor_loss\",\n\u001b[0;32m--> 123\u001b[0;31m                               data=actor_loss)\n\u001b[0m\u001b[1;32m    124\u001b[0m         tf.summary.scalar(name=self.policy_name+\"/critic_loss\",\n\u001b[1;32m    125\u001b[0m                           data=critic_loss)\n",
      "\u001b[0;32m~/Documents/programming/bark-ml/bark_ml/python_wrapper/venv/lib/python3.7/site-packages/tensorboard/plugins/scalar/summary_v2.py\u001b[0m in \u001b[0;36mscalar\u001b[0;34m(name, data, step, description)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mtensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msummary_metadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         )\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/programming/bark-ml/bark_ml/python_wrapper/venv/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(tag, tensor, step, metadata, name)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     op = smart_cond.smart_cond(\n\u001b[0;32m--> 675\u001b[0;31m         _should_record_summaries_v2(), record, _nothing, name=\"summary_cond\")\n\u001b[0m\u001b[1;32m    676\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/programming/bark-ml/bark_ml/python_wrapper/venv/lib/python3.7/site-packages/tensorflow/python/framework/smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`false_fn` must be callable.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m   \u001b[0mpred_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_constant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/programming/bark-ml/bark_ml/python_wrapper/venv/lib/python3.7/site-packages/tensorflow/python/framework/smart_cond.py\u001b[0m in \u001b[0;36msmart_constant_value\u001b[0;34m(pred)\u001b[0m\n\u001b[1;32m     73\u001b[0m   \"\"\"\n\u001b[1;32m     74\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mpred_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;31m# TODO(skyewm): consider folding this into tensor_util.constant_value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/programming/bark-ml/bark_ml/python_wrapper/venv/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mconstant_value\u001b[0;34m(tensor, partial)\u001b[0m\n\u001b[1;32m    820\u001b[0m   \"\"\"\n\u001b[1;32m    821\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/programming/bark-ml/bark_ml/python_wrapper/venv/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \"\"\"\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/programming/bark-ml/bark_ml/python_wrapper/venv/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load params from the json file to create the parameter server object\n",
    "params = ParameterServer(filename=\"data/params/gail_params.json\")\n",
    "\n",
    "# customized parameters:\n",
    "params[\"ML\"][\"Settings\"][\"GPUUse\"] = gpu\n",
    "params[\"ML\"][\"GAILRunner\"][\"tf2rl\"][\"max_steps\"] = max_steps\n",
    "params[\"ML\"][\"GAILRunner\"][\"tf2rl\"][\"test_interval\"] = test_interval\n",
    "params[\"ML\"][\"GAILRunner\"][\"tf2rl\"][\"test_episodes\"] = test_episodes\n",
    "if params[\"ML\"][\"BehaviorGAILAgent\"][\"WarmUp\"] > max_steps / 2:\n",
    "    params[\"ML\"][\"BehaviorGAILAgent\"][\"WarmUp\"] = max_steps / 2\n",
    "\n",
    "# create some logging dirs if they are not present already\n",
    "Path(params[\"ML\"][\"GAILRunner\"][\"tf2rl\"][\"logdir\"]).mkdir(exist_ok=True, parents=True)\n",
    "Path(params[\"ML\"][\"GAILRunner\"][\"tf2rl\"][\"model_dir\"]).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# create environment\n",
    "bp = ContinuousMergingBlueprint(params,\n",
    "                              number_of_senarios=500,\n",
    "                              random_seed=0)\n",
    "env = SingleAgentRuntime(blueprint=bp,\n",
    "                      render=False)\n",
    "\n",
    "# wrapped environment for compatibility with tf2rl\n",
    "wrapped_env = TF2RLWrapper(env, \n",
    "normalize_features=params[\"ML\"][\"Settings\"][\"NormalizeFeatures\"])\n",
    "\n",
    "# instantiate the GAIL agent\n",
    "gail_agent = BehaviorGAILAgent(environment=wrapped_env,\n",
    "                           params=params)\n",
    "\n",
    "# load the expert trajectories\n",
    "expert_trajectories = load_expert_trajectories(\n",
    "    params[\"ML\"][\"GAILRunner\"][\"tf2rl\"][\"expert_path_dir\"],\n",
    "    normalize_features=params[\"ML\"][\"Settings\"][\"NormalizeFeatures\"],\n",
    "    env=env # the unwrapped env has to be used, since that contains the unnormalized spaces.\n",
    "    ) \n",
    "\n",
    "# instantiate a runner that is going to train the agent.\n",
    "runner = GAILRunner(params=params,\n",
    "                 environment=wrapped_env,\n",
    "                 agent=gail_agent,\n",
    "                 expert_trajs=expert_trajectories)\n",
    "\n",
    "# train the agent\n",
    "runner.Train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trained agent visualization:\n",
    "Please set up the number of scenarios to visualize in the next cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of scenarios to visualize:\n",
    "num_scenarios_to_visualize = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'show_test_progress' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-be02a1fec79f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ML\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"GAILRunner\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tf2rl\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_interval\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ML\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"GAILRunner\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tf2rl\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_episodes\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_episodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ML\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"GAILRunner\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tf2rl\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"show_test_progress\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshow_test_progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ML\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"BehaviorGAILAgent\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"WarmUp\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_steps\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ML\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"BehaviorGAILAgent\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"WarmUp\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_steps\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'show_test_progress' is not defined"
     ]
    }
   ],
   "source": [
    "# load params from the json file to create the parameter server object\n",
    "params = ParameterServer(filename=\"data/params/gail_params.json\")\n",
    "\n",
    "# setting the path for the pretrained agent.\n",
    "params[\"ML\"][\"GAILRunner\"][\"tf2rl\"][\"model_dir\"] = os.path.join('data', 'pretrained_agent')\n",
    "\n",
    "# customized parameters:\n",
    "params[\"ML\"][\"Settings\"][\"GPUUse\"] = gpu\n",
    "params[\"ML\"][\"GAILRunner\"][\"tf2rl\"][\"max_steps\"] = max_steps\n",
    "params[\"ML\"][\"GAILRunner\"][\"tf2rl\"][\"test_interval\"] = test_interval\n",
    "params[\"ML\"][\"GAILRunner\"][\"tf2rl\"][\"test_episodes\"] = test_episodes\n",
    "if params[\"ML\"][\"BehaviorGAILAgent\"][\"WarmUp\"] > max_steps / 2:\n",
    "    params[\"ML\"][\"BehaviorGAILAgent\"][\"WarmUp\"] = max_steps / 2\n",
    "\n",
    "# create some logging dirs if they are not present already\n",
    "Path(params[\"ML\"][\"GAILRunner\"][\"tf2rl\"][\"logdir\"]).mkdir(exist_ok=True, parents=True)\n",
    "Path(params[\"ML\"][\"GAILRunner\"][\"tf2rl\"][\"model_dir\"]).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# create environment\n",
    "bp = ContinuousMergingBlueprint(params,\n",
    "                              number_of_senarios=500,\n",
    "                              random_seed=0)\n",
    "env = SingleAgentRuntime(blueprint=bp,\n",
    "                      render=False)\n",
    "\n",
    "# wrapped environment for compatibility with tf2rl\n",
    "wrapped_env = TF2RLWrapper(env, \n",
    "normalize_features=params[\"ML\"][\"Settings\"][\"NormalizeFeatures\"])\n",
    "\n",
    "# instantiate the GAIL agent\n",
    "gail_agent = BehaviorGAILAgent(environment=wrapped_env,\n",
    "                           params=params)\n",
    "\n",
    "# load the expert trajectories\n",
    "expert_trajectories = load_expert_trajectories(\n",
    "    params[\"ML\"][\"GAILRunner\"][\"tf2rl\"][\"expert_path_dir\"],\n",
    "    normalize_features=params[\"ML\"][\"Settings\"][\"NormalizeFeatures\"],\n",
    "    env=env # the unwrapped env has to be used, since that contains the unnormalized spaces.\n",
    "    ) \n",
    "\n",
    "# instantiate a runner that is going to train the agent.\n",
    "runner = GAILRunner(params=params,\n",
    "                 environment=wrapped_env,\n",
    "                 agent=gail_agent,\n",
    "                 expert_trajs=expert_trajectories)\n",
    "\n",
    "# Visualize the agent\n",
    "runner.Visualize(num_scenarios_to_visualize, renderer=\"matplotlib_jupyter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
